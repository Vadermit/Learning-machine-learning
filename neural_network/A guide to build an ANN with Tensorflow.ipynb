{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A guide to build an ANN with Tensorflow\n",
    "\n",
    "First, let's see how Tensorflow works by a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Variables and Constants\n",
    "Before defining the operations, we need to define the variables and constants may be involved in those operations first.\n",
    "* The definition of constant in Tensorflow：in tensorflow, we just use the **tf.constant(init, name='xxx')** to define a constant where **init** is the value of that constant, and **name** is the name string of the constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(2, name = 'cons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The definition of variables with initial value: in tensorflow, if we want to define a variable and we know its initial value then we can initialize it usin the function **tf.Variable(init, name='xxx')** where **init** is the initial value of the variable and **name** is an optional string name of that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.Variable(2, name = 'b')\n",
    "c = tf.Variable(1, name = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The definition of variables with out initial value: if we want to define some Tensorflow variables, and we don't know the initial value of those variables yet, then we need to define a variable container. The Tensorflow function **tf.placeholder(dtype, size, name)** will give us a tensor objec without initial values. **dtype** denote the data type of the elements in Tensor object(variable), **size** defines the size of the tensor and **name** of course denotes the string name of the Tensor object(variable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 1], name = 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the **size** parameter here in the function **tf.placeholder()**. The **size** is a list with the structure **[batchSize, dataSize]**, so **None** in the example above is actually the batch size which means we can set the batch size to any number and **1** is the data size which means that the inputs to later operations are a series(batch) of scalars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Operations\n",
    "We want them to do some calculations using the variables and constants defined above and derive some outputs. So we need to define those operation next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = tf.add(a, b, name = 'op1')\n",
    "op2 = tf.add(a, c, name = 'op2')\n",
    "op3 = tf.multiply(op1, op2, name = 'output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the operations above, we set three operations to perform $(a + b)(a + c)$.\n",
    "\n",
    "Now it's time to run these operations and derive our outputs. But before that, we need to initialize our variables, constants and operations defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the operations between the variables, we need to start a TensorFlow session – tf.Session.  The TensorFlow session is an object where all operations are run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable op3 is 12\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # run initialization\n",
    "    sess.run(init)\n",
    "    # compute the output\n",
    "    output = sess.run(op3)\n",
    "    print(\"Variable op3 is %d\"%(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can see that we don't need to run **op1** and **op2** manually, we only have to run the final operation **op3**, Tensorflow will automatically find out what other operations it depends on, and will run them before running **op3**. And finally we get the correct answer we wanted: $(1+2)\\times(2+2) = 12$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using batch for multiple inputs\n",
    "We can actually feed multiple inputs to the operations at the same time and gets multiple outputs. We can do this by the aforementioned **tf.placeholder**. \n",
    "\n",
    "Now we want to perform the same operations defined above, but this time, there will be multiple **b** inputs feed into the operation.\n",
    "\n",
    "First, define the variables and constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(2, name = 'cons')\n",
    "b = tf.placeholder(tf.int32, [None, 1], name = 'b')\n",
    "c = tf.Variable(1, name = 'c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "op1 = tf.add(a, b, name = 'op1')\n",
    "op2 = tf.add(a, c, name = 'op2')\n",
    "op3 = tf.multiply(op1, op2, name = 'output')\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run operations with **tf.Session()**. As mentioned before, the variable **b** defined by **tf.placeholder** doesn't have inital values, so we need to feed in the values before we run operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inputs b is:\n",
      "[[0]\n",
      " [1]\n",
      " [2]\n",
      " [3]\n",
      " [4]]\n",
      "Variable op3 is:\n",
      "[[ 6]\n",
      " [ 9]\n",
      " [12]\n",
      " [15]\n",
      " [18]]\n"
     ]
    }
   ],
   "source": [
    "b_val = np.arange(0, 5)[:, np.newaxis]\n",
    "with tf.Session() as sess:\n",
    "    # run initialization\n",
    "    sess.run(init)\n",
    "    # compute the output\n",
    "    output = sess.run(op3, feed_dict = {b: b_val})\n",
    "    print('The inputs b is:')\n",
    "    print(sess.run(b, feed_dict = {b: np.arange(0, 5)[:, np.newaxis]}))\n",
    "    print(\"Variable op3 is:\")\n",
    "    print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **[:, np.newaxis]** actually turns a (5, ) sized numpy ndarray to size (5, 1). 5 inidicates that there are 5 samples in one batch, and 1 indicates that the input to the operations are scalars. Let's take a look at how the np.newaxis works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(10)\n",
    "print(a.shape)\n",
    "b = a[:, np.newaxis]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "(1, 5)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "print(a.shape)\n",
    "b = a[np.newaxis, :]\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a three layer ANN with Tensorflow\n",
    "Now we know how the tensorflow works, we will then set up a three layer Artificial Neural Network using Tensorflow.\n",
    "\n",
    "Again, we will use the famous **MNIST** digits dataset to test our ANN. Detials of the dataset can be find in Notebook **A comprehensive guide to learn BP Artificail Neural Networks**. \n",
    "\n",
    "Since each digits in **MNIST** is represented by a $(8\\times8)$ image, the inputs to the ANN would be vectors of length $8\\times8 = 64$. The number of hidden layer neurons would be 32. And the output would be a vector of length 10, each element of which represents the probability of the image being that specific digits. \n",
    "\n",
    "### First things first, define the variables in the ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 64], name = 'X')\n",
    "y = tf.placeholder(tf.float32, [None, 10], name = 'y')\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([64, 32], stddev = 0.03), name = 'W1')\n",
    "b1 = tf.Variable(tf.random_normal([32]), name = 'b1')\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([32, 10], stddev = 0.03), name = 'W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name = 'b2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the operations in the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_output = tf.nn.relu(tf.add(tf.matmul(X, W1), b1))\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_output, W2), b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cost funtion\n",
    "We use the cross entropy of the predicted probability vector **$y_\\_$** and the actual one-hot vector **$y$** as the cost function. Cross-entropy loss, or log loss, measures the performance of a classification model whose output is a probability value between 0 and 1. Cross-entropy loss increases as the predicted probability diverges from the actual label. So predicting a probability of .012 when the actual observation label is 1 would be bad and result in a high loss value. A perfect model would have a log loss of 0.\n",
    "\n",
    "$$J = -\\frac{1}{m}\\sum_{i=1}^m\\sum_{j=1}^n y_i^{(j)}log(y_{i\\_}^{(j)})+(1-y_i^{(j)})log(1-y_{i\\_}^{(j)})$$\n",
    "Where **$m$** is the batch size and **$n$** is the size of output.\n",
    "\n",
    "As you can see, there is $log(y_\\_)$ and $log(1-y_\\_)$ in the cost function, so the elements in the predicted probability vector can not be either 0 or 1, so we need to limit **$y_\\_$** in range $(0, 1)$ using the Tensorflow fucntion **tf.clip_by_value(tensor, min, max)**. Any values less than **min** are set to **min**. Any values greater than **max** are set to **max**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped)\n",
    "                         + (1 - y) * tf.log(1 - y_clipped), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set optimiser\n",
    "Tensorflow provides us a series of neural network training optimsers in https://www.tensorflow.org/api_docs/python/tf/train, and we willl use the gradient descent optimiser here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0915 11:47:11.008346 17280 deprecation.py:323] From C:\\Users\\lenovo\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation\n",
    "After all the variables involved in the neural network defined, we can initialise the Tensorflow graph by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "Before we run the neural network using the Session() function, we need to load our dataset first. For details of the dataset, see Notebook **A comprehensive guide to learn BP neural networks**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of images is:\n",
      "(1797, 8, 8)\n",
      "Size of datas is:\n",
      "(1797, 64)\n",
      "Size of targets is:\n",
      "(1797,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "digits = load_digits()   #load the dataset from sklearn\n",
    "images = digits.images\n",
    "datas = digits.data\n",
    "targets = digits.target\n",
    "\n",
    "print('Size of images is:')\n",
    "print(images.shape)\n",
    "print('Size of datas is:')\n",
    "print(datas.shape)\n",
    "print('Size of targets is:')\n",
    "print(targets.shape)\n",
    "\n",
    "plt.matshow(images[0]) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to standardize those inputs to $(-1, 1)$ first so that it will help the training of ANN convergent. We will use the function **StandardScaler** from sklearn to help us scaling the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.         -0.33501649 -0.04308102  0.27407152 -0.66447751]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "InputScaling = StandardScaler()\n",
    "transX = InputScaling.fit_transform(datas)\n",
    "print(transX[0][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we do not use 0-9 integers in the ANN as output, instead, we use an one-hot vector of lenth 10 to indicate the corresponding digits. By the word **one-hot** I mean it's a binary vector with only one element of which is 1 and others are 0. For example, I can use vector **[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]** to indicate digit 1, and use **[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]** to indicate digit 3. So I need to write a function to transform those targets into one-hot vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of the image above is transformed to:\n",
      "Tensor(\"strided_slice:0\", shape=(10,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def num2vect(y):\n",
    "    y_vect = np.zeros((len(y), 10))\n",
    "    for i in range(len(y)):\n",
    "        y_vect[i, y[i]] = 1\n",
    "    return y_vect\n",
    "transy = num2vect(targets)\n",
    "print('The label of the image above is transformed to:')\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to use a function **train_test_split** from sklearn to randomly choose some elements in **datas** and **targets** as traning set and make the remains as test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1257, 64)\n",
      "[ 0.         -0.33501649 -1.09493684  0.98034282 -1.13109185]\n",
      "(1257, 10)\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(transX, transy, test_size=0.3)\n",
    "print(X_train.shape)\n",
    "print(X_train[0][0:5])\n",
    "print(y_train.shape)\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will use batch gradient descent approach to optimise those parameters(variables) in the neural network, we need to write a function to randomly chose a batch of samples from our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_random_batch(batchSize, X, y):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    idx = np.arange(0 , len(X))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:batchSize]\n",
    "    X_shuffle = [X[i] for i in idx]\n",
    "    y_shuffle = [y[i] for i in idx]\n",
    "    return np.asarray(X_shuffle), np.asarray(y_shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a small demo of how the function **next_random_batch** work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set X is:\n",
      "[[ 0  1  2]\n",
      " [ 3  4  5]\n",
      " [ 6  7  8]\n",
      " [ 9 10 11]\n",
      " [12 13 14]\n",
      " [15 16 17]]\n",
      "Their corresponding label is:\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]]\n",
      "X in a batch is\n",
      "[[ 3  4  5]\n",
      " [15 16 17]\n",
      " [ 6  7  8]]\n",
      "Their corresponding label is:\n",
      "[[ 4  5  6  7]\n",
      " [20 21 22 23]\n",
      " [ 8  9 10 11]]\n"
     ]
    }
   ],
   "source": [
    "btest_X = np.arange(0, 18).reshape(6, 3)\n",
    "btest_y = np.arange(0, 24).reshape(6, 4)\n",
    "batch_X, batch_y = next_random_batch(3, btest_X, btest_y)\n",
    "print('Test set X is:')\n",
    "print(btest_X)\n",
    "print('Their corresponding label is:')\n",
    "print(btest_y)\n",
    "print('X in a batch is')\n",
    "print(batch_X)\n",
    "print('Their corresponding label is:')\n",
    "print(batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the ANN with Tensorflow Session()\n",
    "Now we have all the preparation, we will run the training process(the optimisation operation) to train an ANN to perform digits recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 finished! Cross entropy is 0.084075\n",
      "Epoch 11 finished! Cross entropy is 0.017558\n",
      "Epoch 11 finished! Cross entropy is 0.007733\n",
      "Epoch 11 finished! Cross entropy is 0.011397\n",
      "Epoch 11 finished! Cross entropy is 0.005167\n",
      "Epoch 11 finished! Cross entropy is 0.003343\n",
      "Epoch 11 finished! Cross entropy is 0.002296\n",
      "Epoch 11 finished! Cross entropy is 0.001973\n",
      "Epoch 11 finished! Cross entropy is 0.001973\n",
      "Epoch 11 finished! Cross entropy is 0.000977\n",
      "The recognition accuracy in the testset is 0.972222\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "NN_name = 'mnist_ann'\n",
    "epoch = 10\n",
    "batchSize = 100\n",
    "batchNum = int(datas.shape[0] / batchSize)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    #Start training\n",
    "    for e in range(epoch):\n",
    "        for b in range(batchNum):\n",
    "            mean_ce = 0\n",
    "            XBatch, yBatch = next_random_batch(batchSize, X_train, y_train)\n",
    "            ce, _ = sess.run([cross_entropy, optimiser], feed_dict = {X: XBatch, y: yBatch})\n",
    "            mean_ce += ce/batchNum\n",
    "        print('Epoch %d finished! Cross entropy is %f'%(epoch + 1, mean_ce))\n",
    "    # Validation\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1)), tf.float32))\n",
    "    acc = sess.run(accuracy, feed_dict = {X: X_test, y: y_test})\n",
    "    print('The recognition accuracy in the testset is %f'%(acc))\n",
    "    \n",
    "    #Save model\n",
    "    file_path= './'+ NN_name + '/'\n",
    "    if not os.path.exists(file_path):\n",
    "        os.mkdir(file_path)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, file_path+ 'model.checkpoint')\n",
    "    print('Model saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognise digits with the trained ANN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "The real digit is 0\n",
      "Recognised as 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_name = 'mnist_ann'\n",
    "i = 0\n",
    "digData = transX[i][np.newaxis, :]\n",
    "diglabel = transy[i][np.newaxis, :]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_path = './' + NN_name + '/'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, file_path+ 'model.checkpoint')\n",
    "    print('Model loaded')\n",
    "    vec_rec = sess.run(y_, feed_dict = {X: digData})\n",
    "    y_rec = np.argmax(vec_rec)\n",
    "    print('The real digit is %d'%(np.argmax(diglabel)))\n",
    "    print('Recognised as %d'%(y_rec))\n",
    "    plt.matshow(images[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4, 5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad = np.array([1,2,3,4,5])[np.newaxis, :]\n",
    "ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "The real digit is 1\n",
      "Recognised as 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_name = 'mnist_ann'\n",
    "i = 1\n",
    "digData = transX[i][np.newaxis, :]\n",
    "diglabel = transy[i][np.newaxis, :]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_path = './' + NN_name + '/'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, file_path+ 'model.checkpoint')\n",
    "    print('Model loaded')\n",
    "    vec_rec = sess.run(y_, feed_dict = {X: digData})\n",
    "    y_rec = np.argmax(vec_rec)\n",
    "    print('The real digit is %d'%(np.argmax(diglabel)))\n",
    "    print('Recognised as %d'%(y_rec))\n",
    "    plt.matshow(images[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "The real digit is 2\n",
      "Recognised as 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_name = 'mnist_ann'\n",
    "i = 2\n",
    "digData = transX[i][np.newaxis, :]\n",
    "diglabel = transy[i][np.newaxis, :]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_path = './' + NN_name + '/'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, file_path+ 'model.checkpoint')\n",
    "    print('Model loaded')\n",
    "    vec_rec = sess.run(y_, feed_dict = {X: digData})\n",
    "    y_rec = np.argmax(vec_rec)\n",
    "    print('The real digit is %d'%(np.argmax(diglabel)))\n",
    "    print('Recognised as %d'%(y_rec))\n",
    "    plt.matshow(images[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n",
      "The real digit is 3\n",
      "Recognised as 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NN_name = 'mnist_ann'\n",
    "i = 3\n",
    "digData = transX[i][np.newaxis, :]\n",
    "diglabel = transy[i][np.newaxis, :]\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    file_path = './' + NN_name + '/'\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, file_path+ 'model.checkpoint')\n",
    "    print('Model loaded')\n",
    "    vec_rec = sess.run(y_, feed_dict = {X: digData})\n",
    "    y_rec = np.argmax(vec_rec)\n",
    "    print('The real digit is %d'%(np.argmax(diglabel)))\n",
    "    print('Recognised as %d'%(y_rec))\n",
    "    plt.matshow(images[i]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
